{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Churn in Ride Share Company\n",
    "\n",
    "Ben Weintraub, Eddie Ressegue, Maureen Petterson\n",
    "\n",
    "## Intro\n",
    "In an effort to retain ridership at a ride share company, we wanted to predict key factors affecting churn rate. Our dataset was pulled from July 1st, 2014 and contains data spanning the previous 5 months. The 12 features are:\n",
    "- city\n",
    "- sign-up date\n",
    "- last trip date\n",
    "- average distance\n",
    "- average rating by driver\n",
    "- average rating of driver\n",
    "- surge percentage\n",
    "- average surge\n",
    "- trips in first 30 days\n",
    "- luxury car user\n",
    "- phone used for signup\n",
    "- weekday percentage\n",
    "\n",
    "Churn was defined as no activity within the past 30 days, eg, no rides during the month of June. \n",
    "\n",
    "\n",
    "## Exploratory Data Analysis and Data Preparation\n",
    "\n",
    "<b>Data Preparation</b>\n",
    "\n",
    "The dataset was alrady fairly clean, although there were 3 features with varying amounts of null values. \n",
    "\n",
    "<img alt=\"Data\" src='img/data_head.png'>\n",
    "\n",
    "Additionally, some of the features were categorical or contained information that was redundant. We made the following changes to both the train and test data:\n",
    "\n",
    "- We filled in the missing values in 'average rating of driver' with the average rating from the other entries.  16% of the data in this column was missing and we felt this was too much data to drop from our analysis. \n",
    "\n",
    "- There were 201 nulls in the average rating of driver column. Similarly to the average rating by driver feature, we decided to fill in the nulls with the average value from other entries. \n",
    "\n",
    "- There were 396 nulls in the phone column, so we decided to drop those data points. \n",
    "\n",
    "- The city feature had three possible values (Winterfell, Astapor, and King's Landing) and we used one hot encoding to create three separate boolean features, one for each city. \n",
    "\n",
    "- We added a column for churn, with 1/True representing a customer who is not active in the past 30 days and 0 representing a customer who was active in the past 30 days. \n",
    "\n",
    "- We removed sign-up date, as these are all in January. We also removed last trip date as that data was no longer necessary. \n",
    "\n",
    "\n",
    "A screenshot of our cleaned dataset is below\n",
    "\n",
    "<img alt=\"Clean Data\" src='img/data_clean_head.png'>\n",
    "\n",
    "\n",
    "<b>EDA</b>\n",
    "\n",
    "Working on the training set only\n",
    "\n",
    "<img alt=\"Heatmap\" src='img/corr_heatmap.png'>\n",
    "<img alt=\"Histograms\" src='img/histograms_of_features.png'>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Models Investigated\n",
    "\n",
    "We choose 3 different models to test: Neural Networks, Random Forest, and Gradient Boosting Classification. We decided to evaluate our models on the following metrics: Accuracy, Precision, Recall, and the ROC curve. \n",
    "\n",
    "\n",
    "<b> Neural Networks</b>\n",
    "\n",
    "\n",
    "<b> Random Forest</b>\n",
    "\n",
    "\n",
    "<b> Gradient Boosting Classifier</b>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Key Findings\n",
    " ( Identify interpret features that are the most influential in affecting\n",
    "your predictions.)\n",
    "( Consider business decisions that your model may indicate are appropriate.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Work Flow\n",
    "\n",
    "1. Perform any cleaning, exploratory analysis, and/or visualizations to use the\n",
    "provided data for this analysis.\n",
    "   \n",
    "2. Build a predictive model to help determine the probability that a rider will\n",
    "be retained.\n",
    "\n",
    "3. Evaluate the model.  Focus on metrics that are important for your *statistical\n",
    "model*.\n",
    " \n",
    "\n",
    "\n",
    "5. Discuss the validity of your model. Issues such as\n",
    "leakage.  For more on leakage, see [this essay on\n",
    "Kaggle](https://www.kaggle.com/dansbecker/data-leakage), and this paper: [Leakage in Data\n",
    "Mining: Formulation, Detection, and Avoidance](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.365.7769&rep=rep1&type=pdf).\n",
    "\n",
    "6. Repeat 2 - 5 until you have a satisfactory model.\n",
    "\n",
    "7. Consider business decisions that your model may indicate are appropriate.\n",
    "Evaluate possible decisions with metrics that are appropriate for *decision\n",
    "rules*.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
